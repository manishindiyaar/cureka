<!-- Powered by BMAD™ Core -->

<[
\---
title: "Story 1.1: Mobile Voice Agent Integration"
epic: "Epic 1: Voice Assistant Integration"
priority: "High"
status: "Draft"
as_a: "A patient using the mobile app"
so_i_can: "Have real-time voice conversations with AI assistant"
in_order_to: "Get immediate health assistance, book appointments, and receive personalized care"
---

## Story
As a patient using the mobile app, I want to have real-time voice conversations with AI assistant so that I can get immediate health assistance, book appointments, and receive personalized care through natural voice interactions.

## Background
Following the successful implementation of the backend Vapi sessions endpoint (Story 1.1), this story implements the frontend mobile integration. The current chat.tsx screen is empty and needs to be replaced with a comprehensive voice interaction interface. The mobile app must integrate with the Vapi Web SDK to enable real-time voice conversations, replacing the traditional text-based chat with an immersive voice experience.

The backend infrastructure is already in place at `POST /api/v1/sessions/vapi/start` which provides secure Vapi configuration for authenticated patients. This story focuses on consuming that endpoint and implementing the frontend voice interface following React Native + Expo patterns.

## Acceptance Criteria
1. **Vapi Configuration Integration**
   - Call `POST /api/v1/sessions/vapi/start` endpoint with proper JWT authentication
   - Retrieve Vapi configuration including `public_key` and `assistant_id`
   - Handle configuration errors with user-friendly messages
   - Store configuration securely in memory during session

2. **Voice Service Implementation**
   - Install and configure `@vapi-ai/web` SDK for React Native
   - Create voice service to manage Vapi client initialization and lifecycle
   - Implement proper error handling for connection failures
   - Handle real-time audio streaming and device permissions

3. **UI Component Development**
   - Replace empty chat.tsx with comprehensive voice interface
   - Implement visual indicators for listening, thinking, and speaking states
   - Create microphone permission handling and UI feedback
   - Design following app color palette (#1f345a primary, #8c1c24 accent)

4. **Real-time Conversation Management**
   - Handle voice session initiation and termination
   - Process real-time assistant responses and user speech
   - Implement conversation context management
   - Support interruption handling and speech clarity

5. **Session Synchronization**
   - Link voice sessions to authenticated patient account
   - Sync conversation history with backend via session_id
   - Display conversation summaries and action history
   - Ensure seamless integration with existing sessions tab

## Functional Requirements
- **FR1**: Mobile app shall connect to backend `/api/v1/sessions/vapi/start` endpoint with JWT authentication
- **FR2**: Vapi configuration shall be retrieved securely without exposing server-side keys
- **FR3**: Voice interface shall support real-time bidirectional communication
- **FR4**: App shall handle microphone permissions gracefully with user guidance
- **FR5**: Voice conversations shall sync with existing session history
- **FR6**: Interface shall provide clear visual feedback for connection states
- **FR7**: Error messages shall guide users through connection issues
- **FR8**: Voice sessions shall inherit patient context from authentication

## Non-Functional Requirements
- **NFR1**: Voice connection establishment shall complete within 5 seconds
- **NFR2**: Audio latency shall not exceed 200ms for responsive conversations
- **NFR3**: Interface shall remain responsive during voice interactions
- **NFR4**: Battery usage shall be optimized during voice sessions
- **NFR5**: App shall handle network interruptions gracefully
- **NFR6**: Voice functionality shall support React Native iOS and Android

## Technical Context

### Existing Technology Stack
- **Framework**: React Native with Expo Router
- **Language**: TypeScript
- **Navigation**: Expo Router file-based routing
- **State Management**: React hooks and context
- **Authentication**: JWT token-based (secure store)
- **UI Components**: Native base with custom styling

### Mobile App Structure
```
apps/mobile_app/cureka/
├── app/                        # Expo Router directory
│   ├── (tabs)/                # Tab navigation structure
│   │   ├── home.tsx           # Main screen with voice interface
│   │   └── talk.tsx           # Current placeholder implementation
│   └── (chat)/chat.tsx        # Current empty chat screen to replace
├── src/
├── components/                # Reusable UI components
│   └── AIButton.tsx          # Current button component
├── lib/                      # Services and utilities
└── constants/                # App configurations
```

### Key Technical Dependencies
```bash
npm install @vapi-ai/web expo-av expo-permissions
```

### Vapi SDK Configuration
```typescript
interface VapiServiceConfig {
  public_key: string;
  assistant_id: string;
  session_config: {
    web: boolean;
    app: boolean;
    voice_profile_id: string;
  };
}

interface VoiceServiceState {
  isConnected: boolean;
  isListening: boolean;
  isSpeaking: boolean;
  connectionStatus: 'idle' | 'connecting' | 'connected' | 'error';
  currentSessionId: string | null;
}
```

### Backend Endpoint Reference
**Endpoint**: `POST /api/v1/sessions/vapi/start`
**Authentication**: `Bearer {jwt_token}`
**Response**: Vapi configuration for mobile SDK initialization
**Error Handling**: Standard backend error format

## Implementation Steps

### Step 1: Backend Integration Service
```typescript
// apps/mobile_app/cureka/lib/voice.service.ts
import { vapi } from '@vapi-ai/web';

export class VoiceService {
  private vapiClient: any;
  private sessionConfig: VapiServiceConfig | null = null;

  async initializeVoiceSession(patientId: string, jwtToken: string): Promise<void> {
    try {
      // Fetch Vapi configuration from backend
      const configResponse = await this.fetchVapiConfiguration(patientId, jwtToken);

      // Initialize Vapi client
      this.vapiClient = new vapi.WebSDK();
      this.sessionConfig = configResponse.vapi_config;

      // Configure voice agent
      await this.vapiClient.createConferencingExperience({
        apiKey: this.sessionConfig.public_key,
        assistant_id: this.sessionConfig.assistant_id
      });

    } catch (error) {
      console.error('Voice service initialization failed:', error);
      throw this.formatError(error);
    }
  }

  private async fetchVapiConfiguration(patientId: string, jwtToken: string): Promise<any> {
    const apiUrl = process.env.EXPO_PUBLIC_API_URL || 'https://api.cureka.health';
    const response = await fetch(`${apiUrl}/api/v1/sessions/vapi/start`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${jwtToken}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        assistant_id: process.env.EXPO_PUBLIC_VAPI_ASSISTANT_ID,
        patient_context: { patient_id: patientId }
      })
    });

    if (!response.ok) {
      throw new Error(`Backend error: ${response.status}`);
    }

    return response.json();
  }

  async startVoiceSession(): Promise<string> {
    if (!this.vapiClient) {
      throw new Error('Voice service not initialized');
    }

    try {
      const sessionId = await this.vapiClient.startConversation();
      this.updateConnectionStatus('connected', sessionId);
      return sessionId;
    } catch (error) {
      console.error('Voice session start failed:', error);
      throw this.formatError(error);
    }
  }

  endVoiceSession(): void {
    if (this.vapiClient) {
      this.vapiClient.endConversation();
      this.updateConnectionStatus('idle');
    }
  }

  private formatError(error: any): Error {
    const errorMessage = error.message || 'Voice service error';
    return new Error(`Voice Services: ${errorMessage}`);
  }
}
```

### Step 2: React Native Voice Interface Component
```typescript
// apps/mobile_app/cureka/app/(chat)/chat.tsx
import React, { useState, useEffect, useRef } from 'react';
import {
  View,
  Text,
  StyleSheet,
  TouchableOpacity,
  ActivityIndicator,
  Dimensions
} from 'react-native';
import { SafeAreaView } from 'react-native-safe-area-context';
import { Audio } from 'expo-av';
import { MaterialIcons } from '@expo/vector-icons';
import { VoiceService } from '@/lib/voice.service';
import { Colors } from '@/constants/colors';

const { width: screenWidth, height: screenHeight } = Dimensions.get('window');

export default function ChatScreen() {
  const [voiceState, setVoiceState] = useState({
    isConnected: false,
    isListening: false,
    isSpeaking: false,
    status: 'idle' as const,
    sessionId: null as string | null
  });

  const [error, setError] = useState<string | null>(null);
  const voiceService = useRef(new VoiceService()).current;
  const audioPermissionGranted = useRef(false);

  useEffect(() => {
    initializeVoiceSession();
    requestMicrophonePermission();

    return () => {
      // Cleanup on unmount
      if (voiceState.isConnected) {
        voiceService.endVoiceSession();
      }
    };
  }, []);

  const initializeVoiceSession = async () => {
    try {
      setVoiceState(prev => ({ ...prev, status: 'connecting' }));

      // Get JWT token from secure storage
      const jwtToken = await getJwtToken();
      const patientData = await getCurrentPatient();

      await voiceService.initializeVoiceSession(patientData.id, jwtToken);

      setVoiceState(prev => ({ ...prev, status: 'idle' }));
    } catch (error) {
      console.error('Voice initialization failed:', error);
      setVoiceState(prev => ({ ...prev, status: 'error' }));
      setError(error.message || 'Failed to initialize voice services');
    }
  };

  const requestMicrophonePermission = async (): Promise<boolean> => {
    try {
      const { granted } = await Audio.requestPermissionsAsync();
      audioPermissionGranted.current = granted;
      return granted;
    } catch (error) {
      console.error('Microphone permission error:', error);
      return false;
    }
  };

  const handleStartVoiceSession = async () => {
    try {
      if (!audioPermissionGranted.current) {
        const granted = await requestMicrophonePermission();
        if (!granted) {
          setError('Microphone permission is required for voice functionality');
          return;
        }
      }

      setError(null);
      setVoiceState(prev => ({ ...prev, status: 'connecting' }));

      const sessionId = await voiceService.startVoiceSession();

      setVoiceState(prev => ({
        ...prev,
        isConnected: true,
        sessionId: sessionId,
        status: 'connected'
      }));

    } catch (error) {
      console.error('Voice session failed:', error);
      setVoiceState(prev => ({ ...prev, status: 'error' }));
      setError(error.message || 'Voice session could not be started');
    }
  };

  const renderVoiceInterface = () => {
    const { status, isConnected, sessionId } = voiceState;

    return (
      <SafeAreaView style={styles.container}>
        <View style={styles.header}>
          <Text style={styles.title}>AI Health Assistant</Text>
          <Text style={styles.subtitle}>
            Powered by Vapi AI Voice Technology
          </Text>
        </View>

        <View style={styles.mainContent}>
          {/* Connection Status Indicator */}
          <View style={styles.statusContainer}>
            <View style={[
              styles.statusIndicator,
              styles.statusColors[status]
            ]} />
            <Text style={styles.statusText}>
              {status === 'idle' && 'Ready to connect'}
              {status === 'connecting' && 'Connecting to AI...'}
              {status === 'connected' && 'Connected - Talk to Assistant'}
              {status === 'error' && 'Connection Error'}
            </Text>
          </View>

          {/* Voice Interactive Area */}
          <View style={styles.voiceArea}>
            {status === 'connecting' && (
              <ActivityIndicator size="large" color={Colors.primary} />
            )}

            {status === 'connected' && (
              <TouchableOpacity
                style={styles.voiceButton}
                onPress={handleEndVoiceSession}
              >
                <MaterialIcons name="mic-off" size={48} color="white" />
                <Text style={styles.buttonText}>End Voice Session</Text>
              </TouchableOpacity>
            )}

            {status === 'idle' && (
              <TouchableOpacity
                style={styles.voiceButton}
                onPress={handleStartVoiceSession}
              >
                <MaterialIcons name="mic" size={48} color="white" />
                <Text style={styles.buttonText}>Start Voice Session</Text>
              </TouchableOpacity>
            )}

            {status === 'error' && (
              <View style={styles.errorContainer}>
                <TouchableOpacity
                  style={[styles.voiceButton, styles.retryButton]}
                  onPress={handleStartVoiceSession}
                >
                  <MaterialIcons name="refresh" size={36} color="white" />
                  <Text style={styles.buttonText}>Retry Connection</Text>
                </TouchableOpacity>
              </View>
            )}
          </View>

          {/* Session Information */}
          {sessionId && (
            <View style={styles.sessionInfo}>
              <Text style={styles.sessionText}>Session ID: {sessionId}</Text>
            </View>
          )}

          {/* Error Display */}
          {error && (
            <View style={styles.errorBanner}>
              <Text style={styles.errorText}>{error}</Text>
            </View>
          )}
        </View>
      </SafeAreaView>
    );
  };

  return renderVoiceInterface();
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: Colors.background,
  },
  header: {
    paddingHorizontal: 20,
    paddingTop: 20,
    paddingBottom: 30,
  },
  title: {
    fontSize: 24,
    fontWeight: 'bold',
    color: Colors.text,
    textAlign: 'center',
    marginBottom: 8,
  },
  subtitle: {
    fontSize: 16,
    color: Colors.textSecondary,
    textAlign: 'center',
  },
  mainContent: {
    flex: 1,
    paddingHorizontal: 20,
  },
  statusContainer: {
    flexDirection: 'row',
    alignItems: 'center',
    marginBottom: 40,
    paddingHorizontal: 20,
  },
  statusIndicator: {
    width: 12,
    height: 12,
    borderRadius: 6,
    marginRight: 10,
  },
  statusColors: {
    idle: {
      backgroundColor: Colors.gray[400],
    },
    connecting: {
      backgroundColor: Colors.warning,
    },
    connected: {
      backgroundColor: Colors.success,
    },
    error: {
      backgroundColor: Colors.danger,
    },
  },
  statusText: {
    fontSize: 14,
    color: Colors.textSecondary,
  },
  voiceArea: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
  },
  voiceButton: {
    backgroundColor: Colors.primary,
    borderRadius: 60,
    width: 120,
    height: 120,
    justifyContent: 'center',
    alignItems: 'center',
    elevation: 5,
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 2 },
    shadowOpacity: 0.2,
    shadowRadius: 3.84,
  },
  retryButton: {
    backgroundColor: Colors.danger,
  },
  buttonText: {
    color: 'white',
    fontSize: 14,
    fontWeight: '500',
    marginTop: 8,
  },
  sessionInfo: {
    padding: 20,
    alignItems: 'center',
  },
  sessionText: {
    fontSize: 12,
    color: Colors.textSecondary,
    fontFamily: 'monospace',
  },
  errorBanner: {
    backgroundColor: Colors.danger + '20',
    padding: 16,
    borderRadius: 8,
    marginTop: 20,
  },
  errorText: {
    color: Colors.danger,
    fontSize: 14,
    textAlign: 'center',
  },
});

// Helper functions (would be imported from auth service)
async function getJwtToken(): Promise<string> {
  // Implementation to retrieve JWT from secure storage
  return 'jwt-token-placeholder';
}

async function getCurrentPatient(): Promise<any> {
  // Implementation to retrieve current patient data
  return { id: 'patient-id-placeholder' };
}
```

### Step 3: Environment Configuration
```env
# apps/mobile_app/cureka/.env.local
EXPO_PUBLIC_API_URL=https://api.cureka.health
EXPO_PUBLIC_VAPI_ASSISTANT_ID=your-vapi-assistant-id
```

### Step 4: Audio Permissions Setup
Add to `app.json`:
```json
{
  "expo": {
    "plugins": [
      [
        "expo-av",
        {
          "microphonePermission": "Allow Cureka to access your microphone for voice conversations with our AI health assistant."
        }
      ]
    ]
  }
}
```

## Testing Strategy

### Unit Tests
```typescript
// apps/mobile_app/cureka/__tests__/unit/voice.service.test.ts
describe('VoiceService', () => {
  let voiceService: VoiceService;

  beforeEach(() => {
    voiceService = new VoiceService();
  });

  test('should initialize voice session successfully', async () => {
    // Mock fetch and Vapi client
    const mockJwt = 'test-jwt-token';
    const mockPatientId = 'test-patient-id';

    const result = await voiceService.initializeVoiceSession(mockPatientId, mockJwt);

    expect(result).toBeDefined();
    expect(voiceService['vapiClient']).toBeTruthy();
  });

  test('should handle voice session errors gracefully', async () => {
    const mockJwt = 'invalid-jwt';
    const mockPatientId = 'test-patient-id';

    await expect(voiceService.initializeVoiceSession(mockPatientId, mockJwt))
      .rejects.toThrow('Voice Services:');
  });
});
```

### Integration Tests
- Test integration with backend endpoint
- Test Vapi SDK integration and session management
- Test audio permissions and device compatibility
- Test voice session persistence and cleanup

### Error Handling Tests
- Network timeout scenarios
- Invalid JWT token scenarios
- Microphone permission denial
- Vapi SDK initialization failures

## Security Considerations
1. **JWT Token Security**: Tokens stored in secure storage, never in plain text
2. **Vapi Public Key**: Public key exposure is safe; secret keys remain on backend
3. **Session Isolation**: Each patient gets isolated voice session
4. **Permission Handling**: Microphone permissions explicitly requested
5. **Data Validation**: Backend validates all session requests

## Performance Requirements
- Voice session initialization: < 3 seconds
- Audio latency: < 200ms
- Memory usage during conversation: < 50MB additional overhead
- Session cleanup: Automatic within 5 seconds of disconnect

## Definition of Done
- [ ] Vapi configuration retrieval from backend working
- [ ] Voice service module implemented and tested
- [ ] Microphone permissions handled properly
- [ ] Voice interface replaces empty chat screen
- [ ] Session synchronization with backend implemented
- [ ] Error handling with user-friendly messages
- [ ] Performance criteria met (< 5s connection, < 200ms latency)
- [ ] Integration tests covering all major flows
- [ ] Documentation updated with deployment guides
- [ ] Accessibility support implemented (screen readers, large text)

## Post-Implementation Notes
- Monitor voice session success rates and connection times
- Test with various network conditions (2G, 3G, 4G, WiFi)
- Review Vapi usage logs for optimization opportunities
- Consider localization for voice interactions in multiple languages